{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "516df156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f1a364",
   "metadata": {},
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eefcc93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel(\"train.xlsx\")\n",
    "train.drop_duplicates(inplace = True)\n",
    "train.reset_index(drop = True, inplace = True)\n",
    "train[\"Average_Cost\"] = train.Average_Cost.apply(lambda x : ''.join(x.split('₹')[1:]))\n",
    "train['Average_Cost'] = train['Average_Cost'].str.replace(',', '')\n",
    "train['Average_Cost'] = pd.to_numeric(train['Average_Cost'])\n",
    "train[\"Minimum_Order\"] = train.Minimum_Order.apply(lambda x : ''.join(x.split('₹')[1:]))\n",
    "train['Minimum_Order'] = pd.to_numeric(train['Minimum_Order'])\n",
    "train['Rating'] = pd.to_numeric(train['Rating'], errors = 'coerce')\n",
    "train['Votes'] = pd.to_numeric(train['Votes'], errors = 'coerce')\n",
    "train['Reviews'] = pd.to_numeric(train['Reviews'], errors = 'coerce')\n",
    "train['Average_Cost'] = train['Average_Cost'].fillna(train['Average_Cost'].mean())\n",
    "train['Rating'] = train['Rating'].fillna(0)\n",
    "train['Votes'] = train['Votes'].fillna(0)\n",
    "train['Reviews'] = train['Reviews'].fillna(0)\n",
    "train['Minimum_To_Cost_Ratio'] = train['Minimum_Order']/train['Average_Cost']\n",
    "train['Branches'] = train['Restaurant'].map(train['Restaurant'].value_counts())\n",
    "train['Restaurants_Count'] = train['Location'].map(train['Location'].value_counts())\n",
    "train.drop(['Restaurant'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5def543",
   "metadata": {},
   "outputs": [],
   "source": [
    "city = []\n",
    "for location in train.Location:\n",
    "    if \"Pune\" in location:\n",
    "        city.append(\"Pune\")\n",
    "    elif \"Bangalore\" in location:\n",
    "        city.append(\"Bangalore\")\n",
    "    elif \"Hyderabad\" in location:\n",
    "        city.append(\"Hyderabad\")\n",
    "    elif \"Noida\" in location:\n",
    "        city.append(\"Noida\")\n",
    "    elif \"Kolkata\" in location:\n",
    "        city.append(\"Kolkata\")\n",
    "    elif \"Delhi\" in location:\n",
    "        city.append(\"Delhi\")\n",
    "    elif \"Marathalli\" in location:\n",
    "        city.append(\"Bangalore\")\n",
    "    elif \"Electronic City\" in location:\n",
    "        city.append(\"Bangalore\")\n",
    "    elif \"Mumbai\" in location:\n",
    "        city.append(\"Mumbai\")\n",
    "    elif \"Whitefield\" in location:\n",
    "        city.append(\"Bangalore\")\n",
    "    elif \"Gurgaon\" in location:\n",
    "        city.append(\"Gurgaon\")\n",
    "    elif \"Gurgoan\" in location:\n",
    "        city.append(\"Gurgaon\")\n",
    "    elif \"Majestic\" in location:\n",
    "        city.append(\"Bangalore\")\n",
    "\n",
    "train['City'] = city"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90b7697",
   "metadata": {},
   "source": [
    "## WINSORIZING OUTLIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8ed7953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# plt.rcParams['figure.figsize'] = (15,7)\n",
    "# f,(ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5)\n",
    "# sns.boxplot(y = 'Average_Cost', data = train, ax = ax1, palette = 'coolwarm')\n",
    "# sns.boxplot(y = 'Minimum_Order', data = train, ax = ax2)\n",
    "# sns.boxplot(y = 'Rating', data = train, ax = ax3, palette = 'coolwarm')\n",
    "# sns.boxplot(y = 'Votes', data = train, ax = ax4)\n",
    "# sns.boxplot(y = 'Reviews', data = train, ax = ax5, palette = 'coolwarm')\n",
    "# f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e241eac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in ['Average_Cost', 'Minimum_Order', 'Rating', 'Votes', 'Reviews']:\n",
    "#     IQR = train[column].quantile(0.75) - train[column].quantile(0.25)\n",
    "#     Lower_fence = train[column].quantile(0.25) - (IQR * 1.5)\n",
    "#     Upper_fence = train[column].quantile(0.75) + (IQR * 1.5)\n",
    "#     print(f'{column} outliers are values < {round(Lower_fence,2)} or > {round(Upper_fence,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "805ac1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['Average_Cost'] = np.where(train['Average_Cost'] > 350.0, 350.0, train['Average_Cost'])\n",
    "# train['Minimum_Order'] = np.where(train['Minimum_Order'] < 50.0, 50.0, train['Minimum_Order'])\n",
    "# train['Minimum_Order'] = np.where(train['Minimum_Order'] > 50.0, 50.0, train['Minimum_Order'])\n",
    "# train['Rating'] = np.where(train['Rating'] < 2.8, 2.8, train['Rating'])\n",
    "# train['Rating'] = np.where(train['Rating'] > 4.4, 4.4, train['Rating'])\n",
    "# train['Votes'] = np.where(train['Votes'] > 370.0, 370.0, train['Votes'])\n",
    "# train['Reviews'] = np.where(train['Reviews'] > 150.0, 150.0, train['Reviews'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd64511",
   "metadata": {},
   "source": [
    "## DUMMIFICATION, MIN-MAX SCALING, LABEL ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a63814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = pd.get_dummies(train['City'], drop_first = True)\n",
    "\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# scaled1 = scaler.fit_transform(train[['Average_Cost', 'Minimum_Order', 'Rating', 'Votes', 'Reviews']])\n",
    "# scaled_df1 = pd.DataFrame(scaled1, columns = ['Average_Cost', 'Minimum_Order', 'Rating', 'Votes', 'Reviews'])\n",
    "\n",
    "X1 = pd.concat([train[['Average_Cost', 'Minimum_Order', 'Rating', 'Votes', 'Reviews', 'Branches']], X1], axis = 1)\n",
    "# X2 = pd.concat([scaled_df1, X1], axis = 1)\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# label_encoder = LabelEncoder()\n",
    "# y = label_encoder.fit_transform(train['Delivery_Time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9851138e",
   "metadata": {},
   "source": [
    "## RANDOM FOREST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7030a6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9907276239536381\n",
      "Test Accuracy: 0.7933313307299489\n"
     ]
    }
   ],
   "source": [
    "# X = train[['Average_Cost', 'Minimum_Order', 'Rating', 'Votes', 'Reviews']]\n",
    "y = train['Delivery_Time']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y, test_size = 0.3, random_state = 1234, shuffle = True)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(random_state = 1234)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "print(\"Train Accuracy:\", accuracy_score(y_train, y_pred_train))\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfeed0c5",
   "metadata": {},
   "source": [
    "## RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34066fc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jadha\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal number of features: 12\n",
      "Best features: Index(['Average_Cost', 'Minimum_Order', 'Rating', 'Votes', 'Reviews',\n",
      "       'Branches', 'Delhi', 'Gurgaon', 'Kolkata', 'Mumbai', 'Noida', 'Pune'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "rfecv = RFECV(estimator = model, step = 1, cv = 5, scoring = 'accuracy')\n",
    "rfecv = rfecv.fit(X_train, y_train)\n",
    "\n",
    "print(\"The optimal number of features:\", rfecv.n_features_)\n",
    "print(\"Best features:\", X_train.columns[rfecv.support_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d662ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.990856406954282\n",
      "Test Accuracy: 0.7918293781916491\n"
     ]
    }
   ],
   "source": [
    "X_train_selected = rfecv.transform(X_train)\n",
    "X_test_selected = rfecv.transform(X_test)\n",
    "\n",
    "model = RandomForestClassifier(random_state = 1234)\n",
    "model.fit(X_train_selected, y_train)\n",
    "y_pred_train = model.predict(X_train_selected)\n",
    "y_pred_test = model.predict(X_test_selected)\n",
    "print(\"Train Accuracy:\", accuracy_score(y_train, y_pred_train))\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47693414",
   "metadata": {},
   "source": [
    "## OPTUNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e566390",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-20 01:42:17,034] A new study created in memory with name: no-name-21399203-0421-4d24-89ca-3fb3dbf2e827\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3da4a150f494126a180438532649b34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-20 01:42:18,252] Trial 0 finished with value: 0.7047161309702613 and parameters: {'n_estimators': 280, 'max_depth': 4, 'min_samples_split': 17, 'min_samples_leaf': 3, 'max_features': 'log2', 'criterion': 'entropy', 'bootstrap': False, 'class_weight': None}. Best is trial 0 with value: 0.7047161309702613.\n",
      "[I 2023-06-20 01:42:19,583] Trial 1 finished with value: 0.6740762991889456 and parameters: {'n_estimators': 160, 'max_depth': 19, 'min_samples_split': 11, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'criterion': 'entropy', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 0 with value: 0.7047161309702613.\n",
      "[I 2023-06-20 01:42:20,399] Trial 2 finished with value: 0.7266446380294382 and parameters: {'n_estimators': 160, 'max_depth': 7, 'min_samples_split': 16, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'criterion': 'gini', 'bootstrap': True, 'class_weight': None}. Best is trial 2 with value: 0.7266446380294382.\n",
      "[I 2023-06-20 01:42:21,765] Trial 3 finished with value: 0.6061880444577952 and parameters: {'n_estimators': 180, 'max_depth': 8, 'min_samples_split': 15, 'min_samples_leaf': 9, 'max_features': 'log2', 'criterion': 'entropy', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 2 with value: 0.7266446380294382.\n",
      "[I 2023-06-20 01:42:23,330] Trial 4 finished with value: 0.650045058576149 and parameters: {'n_estimators': 240, 'max_depth': 12, 'min_samples_split': 20, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'criterion': 'gini', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 2 with value: 0.7266446380294382.\n",
      "[I 2023-06-20 01:42:23,796] Trial 5 finished with value: 0.7068188645238811 and parameters: {'n_estimators': 120, 'max_depth': 4, 'min_samples_split': 14, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'criterion': 'gini', 'bootstrap': True, 'class_weight': None}. Best is trial 2 with value: 0.7266446380294382.\n",
      "[I 2023-06-20 01:42:25,477] Trial 6 finished with value: 0.6488434965455092 and parameters: {'n_estimators': 180, 'max_depth': 17, 'min_samples_split': 20, 'min_samples_leaf': 9, 'max_features': 'sqrt', 'criterion': 'gini', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 2 with value: 0.7266446380294382.\n",
      "[I 2023-06-20 01:42:25,661] Trial 7 finished with value: 0.5650345449083809 and parameters: {'n_estimators': 40, 'max_depth': 5, 'min_samples_split': 20, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'criterion': 'entropy', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 2 with value: 0.7266446380294382.\n",
      "[I 2023-06-20 01:42:27,243] Trial 8 finished with value: 0.7542805647341544 and parameters: {'n_estimators': 180, 'max_depth': 18, 'min_samples_split': 19, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'criterion': 'gini', 'bootstrap': False, 'class_weight': None}. Best is trial 8 with value: 0.7542805647341544.\n",
      "[I 2023-06-20 01:42:27,909] Trial 9 finished with value: 0.6533493541604085 and parameters: {'n_estimators': 80, 'max_depth': 11, 'min_samples_split': 18, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'criterion': 'entropy', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 8 with value: 0.7542805647341544.\n",
      "[I 2023-06-20 01:42:29,990] Trial 10 finished with value: 0.756984079303094 and parameters: {'n_estimators': 240, 'max_depth': 15, 'min_samples_split': 12, 'min_samples_leaf': 5, 'max_features': 'log2', 'criterion': 'gini', 'bootstrap': False, 'class_weight': None}. Best is trial 10 with value: 0.756984079303094.\n",
      "[I 2023-06-20 01:42:32,139] Trial 11 finished with value: 0.756984079303094 and parameters: {'n_estimators': 240, 'max_depth': 15, 'min_samples_split': 12, 'min_samples_leaf': 5, 'max_features': 'log2', 'criterion': 'gini', 'bootstrap': False, 'class_weight': None}. Best is trial 10 with value: 0.756984079303094.\n",
      "[I 2023-06-20 01:42:34,153] Trial 12 finished with value: 0.7542805647341544 and parameters: {'n_estimators': 240, 'max_depth': 15, 'min_samples_split': 11, 'min_samples_leaf': 6, 'max_features': 'log2', 'criterion': 'gini', 'bootstrap': False, 'class_weight': None}. Best is trial 10 with value: 0.756984079303094.\n",
      "[I 2023-06-20 01:42:36,701] Trial 13 finished with value: 0.7539801742264944 and parameters: {'n_estimators': 300, 'max_depth': 14, 'min_samples_split': 13, 'min_samples_leaf': 5, 'max_features': 'log2', 'criterion': 'gini', 'bootstrap': False, 'class_weight': None}. Best is trial 10 with value: 0.756984079303094.\n",
      "[I 2023-06-20 01:42:38,765] Trial 14 finished with value: 0.7542805647341544 and parameters: {'n_estimators': 240, 'max_depth': 15, 'min_samples_split': 10, 'min_samples_leaf': 6, 'max_features': 'log2', 'criterion': 'gini', 'bootstrap': False, 'class_weight': None}. Best is trial 10 with value: 0.756984079303094.\n",
      "[I 2023-06-20 01:42:40,364] Trial 15 finished with value: 0.7410633823971162 and parameters: {'n_estimators': 220, 'max_depth': 11, 'min_samples_split': 13, 'min_samples_leaf': 8, 'max_features': 'log2', 'criterion': 'gini', 'bootstrap': False, 'class_weight': None}. Best is trial 10 with value: 0.756984079303094.\n",
      "[I 2023-06-20 01:42:43,026] Trial 16 finished with value: 0.7599879843796936 and parameters: {'n_estimators': 280, 'max_depth': 20, 'min_samples_split': 12, 'min_samples_leaf': 4, 'max_features': 'log2', 'criterion': 'gini', 'bootstrap': False, 'class_weight': None}. Best is trial 16 with value: 0.7599879843796936.\n",
      "[I 2023-06-20 01:42:45,692] Trial 17 finished with value: 0.7671973565635326 and parameters: {'n_estimators': 280, 'max_depth': 20, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'log2', 'criterion': 'gini', 'bootstrap': False, 'class_weight': None}. Best is trial 17 with value: 0.7671973565635326.\n",
      "[I 2023-06-20 01:42:48,606] Trial 18 finished with value: 0.7668969660558727 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'log2', 'criterion': 'gini', 'bootstrap': False, 'class_weight': None}. Best is trial 17 with value: 0.7671973565635326.\n",
      "[I 2023-06-20 01:42:51,537] Trial 19 finished with value: 0.7668969660558727 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'log2', 'criterion': 'gini', 'bootstrap': False, 'class_weight': None}. Best is trial 17 with value: 0.7671973565635326.\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    param_space = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 40, 300, step=20),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 10, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 3, 10),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
    "        'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy']),\n",
    "        'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n",
    "        'class_weight': trial.suggest_categorical('class_weight', ['balanced', None])\n",
    "    }\n",
    "    \n",
    "    model = RandomForestClassifier(random_state = 1234, **param_space)\n",
    "    model.fit(X_train_selected, y_train)\n",
    "    y_pred_test = model.predict(X_test_selected)\n",
    "    return accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "study = optuna.create_study(direction = 'maximize')\n",
    "study.optimize(objective, n_trials = 20, show_progress_bar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ace27745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 20\n",
      "Best trial:\n",
      "  Value: 0.7671973565635326\n",
      "  Params: \n",
      "    n_estimators: 280\n",
      "    max_depth: 20\n",
      "    min_samples_split: 10\n",
      "    min_samples_leaf: 4\n",
      "    max_features: log2\n",
      "    criterion: gini\n",
      "    bootstrap: False\n",
      "    class_weight: None\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "995ad0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.7886670959433355\n",
      "Test Accuracy: 0.7413637729047762\n"
     ]
    }
   ],
   "source": [
    "# rfr_params = {'n_estimators': 100,\n",
    "#               'max_depth': 21,\n",
    "#               'min_samples_split': 3,\n",
    "#               'min_samples_leaf': 1,\n",
    "#               'max_features': 'sqrt',\n",
    "#               'criterion': 'entropy',\n",
    "#               'bootstrap': True,\n",
    "#               'class_weight': None\n",
    "#              }\n",
    "\n",
    "rfr_params = {'n_estimators': 70,\n",
    "              'max_depth': 10,\n",
    "              'min_samples_split': 10,\n",
    "              'min_samples_leaf': 7,\n",
    "              'max_features': 'log2',\n",
    "              'criterion': 'gini',\n",
    "              'bootstrap': False,\n",
    "              'class_weight': None\n",
    "             }\n",
    "\n",
    "model = RandomForestClassifier(**rfr_params, random_state = 1234)\n",
    "model.fit(X_train_selected, y_train)\n",
    "y_pred_train = model.predict(X_train_selected)\n",
    "y_pred_test = model.predict(X_test_selected)\n",
    "print(\"Train Accuracy:\", accuracy_score(y_train, y_pred_train))\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4aac26",
   "metadata": {},
   "source": [
    "# SUBMISSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1e2785",
   "metadata": {},
   "source": [
    "## PREPROCESSING TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7fcf4904",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_excel(\"test.xlsx\")\n",
    "test[\"Average_Cost\"] = test.Average_Cost.apply(lambda x : ''.join(x.split('₹')[1:]))\n",
    "test['Average_Cost'] = test['Average_Cost'].str.replace(',', '')\n",
    "test['Average_Cost'] = pd.to_numeric(test['Average_Cost'])\n",
    "test[\"Minimum_Order\"] = test.Minimum_Order.apply(lambda x : ''.join(x.split('₹')[1:]))\n",
    "test['Minimum_Order'] = pd.to_numeric(test['Minimum_Order'])\n",
    "test['Rating'] = pd.to_numeric(test['Rating'], errors = 'coerce')\n",
    "test['Votes'] = pd.to_numeric(test['Votes'], errors = 'coerce')\n",
    "test['Reviews'] = pd.to_numeric(test['Reviews'], errors = 'coerce')\n",
    "test['Average_Cost'] = test['Average_Cost'].fillna(test['Average_Cost'].mean())\n",
    "test['Rating'] = test['Rating'].fillna(0)\n",
    "test['Votes'] = test['Votes'].fillna(0)\n",
    "test['Reviews'] = test['Reviews'].fillna(0)\n",
    "test['Minimum_To_Cost_Ratio'] = test['Minimum_Order']/test['Average_Cost']\n",
    "test['Branches'] = test['Restaurant'].map(test['Restaurant'].value_counts())\n",
    "test['Restaurants_Count'] = test['Location'].map(test['Location'].value_counts())\n",
    "test.drop(['Restaurant'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cbef005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "city = []\n",
    "for location in test.Location:\n",
    "    if \"Pune\" in location:\n",
    "        city.append(\"Pune\")\n",
    "    elif \"Bangalore\" in location:\n",
    "        city.append(\"Bangalore\")\n",
    "    elif \"Hyderabad\" in location:\n",
    "        city.append(\"Hyderabad\")\n",
    "    elif \"Noida\" in location:\n",
    "        city.append(\"Noida\")\n",
    "    elif \"Kolkata\" in location:\n",
    "        city.append(\"Kolkata\")\n",
    "    elif \"Delhi\" in location:\n",
    "        city.append(\"Delhi\")\n",
    "    elif \"Marathalli\" in location:\n",
    "        city.append(\"Bangalore\")\n",
    "    elif \"Electronic City\" in location:\n",
    "        city.append(\"Bangalore\")\n",
    "    elif \"Mumbai\" in location:\n",
    "        city.append(\"Mumbai\")\n",
    "    elif \"Whitefield\" in location:\n",
    "        city.append(\"Bangalore\")\n",
    "    elif \"Gurgaon\" in location:\n",
    "        city.append(\"Gurgaon\")\n",
    "    elif \"Gurgoan\" in location:\n",
    "        city.append(\"Gurgaon\")\n",
    "    elif \"Majestic\" in location:\n",
    "        city.append(\"Bangalore\")\n",
    "\n",
    "test['City'] = city"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e92d79",
   "metadata": {},
   "source": [
    "## WINSORIZING OUTLIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4db99cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# plt.rcParams['figure.figsize'] = (15,7)\n",
    "# f,(ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5)\n",
    "# sns.boxplot(y = 'Average_Cost', data = test, ax = ax1, palette = 'coolwarm')\n",
    "# sns.boxplot(y = 'Minimum_Order', data = test, ax = ax2)\n",
    "# sns.boxplot(y = 'Rating', data = test, ax = ax3, palette = 'coolwarm')\n",
    "# sns.boxplot(y = 'Votes', data = test, ax = ax4)\n",
    "# sns.boxplot(y = 'Reviews', data = test, ax = ax5, palette = 'coolwarm')\n",
    "# f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3456b0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in ['Average_Cost', 'Minimum_Order', 'Rating', 'Votes', 'Reviews']:\n",
    "#     IQR = test[column].quantile(0.75) - test[column].quantile(0.25)\n",
    "#     Lower_fence = test[column].quantile(0.25) - (IQR * 1.5)\n",
    "#     Upper_fence = test[column].quantile(0.75) + (IQR * 1.5)\n",
    "#     print(f'{column} outliers are values < {round(Lower_fence,2)} or > {round(Upper_fence,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bbd60393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test['Average_Cost'] = np.where(test['Average_Cost'] > 350.0, 350.0, test['Average_Cost'])\n",
    "# test['Minimum_Order'] = np.where(test['Minimum_Order'] < 50.0, 50.0, test['Minimum_Order'])\n",
    "# test['Minimum_Order'] = np.where(test['Minimum_Order'] > 50.0, 50.0, test['Minimum_Order'])\n",
    "# test['Rating'] = np.where(test['Rating'] < 2.4, 2.4, test['Rating'])\n",
    "# test['Votes'] = np.where(test['Votes'] > 481.12, 481.12, test['Votes'])\n",
    "# test['Reviews'] = np.where(test['Reviews'] > 212.0, 212.0, test['Reviews'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bea3c4",
   "metadata": {},
   "source": [
    "## DUMMIFICATION, MIN-MAX SCALING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5bab3580",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = pd.get_dummies(test['City'], drop_first = True)\n",
    "\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# scaled2 = scaler.fit_transform(test[['Average_Cost', 'Minimum_Order', 'Rating', 'Votes', 'Reviews']])\n",
    "# scaled_df2 = pd.DataFrame(scaled2, columns = ['Average_Cost', 'Minimum_Order', 'Rating', 'Votes', 'Reviews'])\n",
    "\n",
    "X2 = pd.concat([test[['Average_Cost', 'Minimum_Order', 'Rating', 'Votes', 'Reviews', 'Branches']], X2], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c710335",
   "metadata": {},
   "source": [
    "## WRITE INTO SUBMISSION FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fc1d92d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = rfecv.transform(X2)\n",
    "test['Delivery_Time'] = model.predict(X2)\n",
    "test['Delivery_Time'].to_excel('submission.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803681c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
